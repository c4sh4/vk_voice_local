{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK143slV2IMJ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install pydub\n",
        "!pip install numpy\n",
        "!apt-get install git-lfs\n",
        "!git lfs install\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSfADcjtktWz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/c4sh4/vk_voice_local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SDf3IPVkv76"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Si31CS59kxOa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
        "from transformers.file_utils import ModelOutput\n",
        "from transformers import Wav2Vec2Processor, AutoModelForAudioClassification\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# my repo\n",
        "from vk_voice_local.ravdess_fast_open import create_RAVDESS_df_with_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3nNA-iIk9aL"
      },
      "outputs": [],
      "source": [
        "drive.mount(r'/content/drive', force_remount=True) # my google disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuEe350NlMVl"
      },
      "outputs": [],
      "source": [
        "df = create_RAVDESS_df_with_labels('drive/MyDrive/vk_voice/datasets/RAVDESS', 16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5Khm94blQmW"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained('patrickvonplaten/wavlm-libri-clean-100h-base-plus')\n",
        "model = AutoModelForAudioClassification.from_pretrained(\"Zahra99/wavlm-large-finetuned-iemocap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NCZOmhecmeF2"
      },
      "outputs": [],
      "source": [
        "cpnfig_ = model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nauZCmAUm9Ww"
      },
      "outputs": [],
      "source": [
        "print(\"Классы, которые есть в Zahra99/wavlm-large-finetuned-iemocap: \")\n",
        "for class_id, class_label in cpnfig_.id2label.items():\n",
        "    print(f\"Class ID: {class_id}, Label: {class_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlr7dYlpnbyn"
      },
      "source": [
        "WavLM, предобученный для SER на AIMOCAP имеет 4 класса:  \n",
        "* 0) Angry\n",
        "* 1) happy\n",
        "* 2) neutral\n",
        "* 3) sad\n",
        "\n",
        "Классы RAVDESS:\n",
        "\n",
        "* 01 = neutral,   \n",
        "* 02 = calm,  \n",
        "* 03 = happy,   \n",
        "* 04 = sad,   \n",
        "* 05 = angry,   \n",
        "* 06 = fearful,   \n",
        "* 07 = disgust,   \n",
        "* 08 = surprised  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Tt4BhpqH3D3f"
      },
      "outputs": [],
      "source": [
        "def predict_emotion_wavlm(audio_np_array, processor, model, device, sampling_rate = 16000):\n",
        "    model.to(device)\n",
        "    # processor\n",
        "    input_values = processor(audio_np_array, return_tensors=\"pt\", sampling_rate=sampling_rate).input_values\n",
        "    input_values = input_values.to(device)\n",
        "\n",
        "    # prediciton\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    predicted_class_id = torch.argmax(logits, dim=-1)\n",
        "    # return predicted_class_id.item()\n",
        "    return model.config.id2label[predicted_class_id.item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aPD6zB8CwDXU"
      },
      "outputs": [],
      "source": [
        "df_test = df[df['label'].isin([1,3,4,5])].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NaYPPRu4w3wP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9214f9-6334-4782-af52-bf81f1dfb49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  audio label\n",
            "4     [9.734966e-06, 4.337436e-07, -4.2628585e-07, 4...     1\n",
            "5     [-5.684342e-14, -1.7053026e-13, 0.0, 3.410605e...     1\n",
            "6     [-4.973799e-14, -2.629008e-13, -1.9895197e-13,...     1\n",
            "7     [1.6705712e-07, 2.1253032e-05, 2.0601543e-05, ...     1\n",
            "8     [-3.0412157e-06, -1.0787139e-05, -1.6587239e-0...     1\n",
            "...                                                 ...   ...\n",
            "1419  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     5\n",
            "1420  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     5\n",
            "1421  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     5\n",
            "1422  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     5\n",
            "1423  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     5\n",
            "\n",
            "[768 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dddvSP7LuA-z"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "true_labels = df_test['label'].tolist()\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    audio_data = row['audio']\n",
        "    predicted_label = predict_emotion_wavlm(audio_data, processor, model, device, 16000)\n",
        "    predicted_labels.append(predicted_label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\n",
        "    \"ang\": 5,  #\n",
        "    \"hap\": 3,  #\n",
        "    \"neu\": 1,  #\n",
        "    \"sad\": 4,  #\n",
        "}"
      ],
      "metadata": {
        "id": "oSk2w2GnwN5G"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"angry\", \"happy\",  \"neutral\", \"sad\"]"
      ],
      "metadata": {
        "id": "89N50ETkz_B1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_predicted_labels = np.array([label_mapping[pred] for pred in predicted_labels])\n",
        "mapped_predicted_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO3lnPrJzMPH",
        "outputId": "b7fa29be-0c3b-440e-bbac-e75f99baaff3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 5,\n",
              "       5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 3, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 1, 5, 5, 5,\n",
              "       5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 3, 3, 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 3, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 5, 1, 1, 5, 5, 1, 1,\n",
              "       5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 5, 5, 1, 1, 1, 5, 1, 5, 5, 1, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 5, 5,\n",
              "       5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 5, 1, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 1,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_labels, mapped_predicted_labels)\n",
        "f1_weighted = f1_score(true_labels, mapped_predicted_labels, average='weighted')\n",
        "precision_weighted = precision_score(true_labels, mapped_predicted_labels, average='weighted', zero_division=0)\n",
        "recall_weighted = recall_score(true_labels, mapped_predicted_labels, average='weighted')\n",
        "\n",
        "f1_per_class = f1_score(true_labels, mapped_predicted_labels, average=None)\n",
        "precision_per_class = precision_score(true_labels, mapped_predicted_labels, average=None, zero_division=0)\n",
        "recall_per_class = recall_score(true_labels, mapped_predicted_labels, average=None)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1_weighted}\")\n",
        "print(f\"Precision: {precision_weighted}\")\n",
        "print(f\"Recall: {recall_weighted}\")\n",
        "\n",
        "print(\"\\nMetrics per class:\")\n",
        "for class_idx, (f1, prec, rec) in enumerate(zip(f1_per_class, precision_per_class, recall_per_class)):\n",
        "    print(f\"Class {class_names[class_idx]} - F1: {f1}, Precision: {prec}, Recall: {rec}\")\n",
        "    # print(class_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ2M9Jlo0KTs",
        "outputId": "5c563531-5511-48de-a5ad-1e2506d2a86f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3854166666666667\n",
            "F1 Score: 0.27718252959331885\n",
            "Precision: 0.4317479537433356\n",
            "Recall: 0.3854166666666667\n",
            "\n",
            "Metrics per class:\n",
            "Class angry - F1: 0.6063829787234043, Precision: 0.6195652173913043, Recall: 0.59375\n",
            "Class happy - F1: 0.04060913705583756, Precision: 0.8, Recall: 0.020833333333333332\n",
            "Class neutral - F1: 0.0, Precision: 0.0, Recall: 0.0\n",
            "Class sad - F1: 0.46173800259403375, Precision: 0.307426597582038, Recall: 0.9270833333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEEaeZkx6iH8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}